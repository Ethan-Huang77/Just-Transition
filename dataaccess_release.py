# -*- coding: utf-8 -*-
"""DataAccess_release.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12lZCoNBdJe-kDhQ4rzdhSHf-Gc-17hiS
"""

#@title Setting things up... run me first

from google.colab import drive
import pandas as pd
import numpy as np
import os
from datetime import datetime, date
from tqdm import tqdm

from collections.abc import MutableMapping
from ast import Return
import ipywidgets as widgets
from IPython.display import display, HTML
import base64
from google.colab import files
import math
import zipfile
import io
# from IPython.display import HTML
import google.colab.data_table
import google.colab.data_table as dt

drive.mount("/content/drive")

global_dfs = []
global_fnames = []
previous_UI_states = {}

def initialize(titles, stations_set_name):
  def read_csv_file(path):
    print(f"\t reading {path}...")
    start_time = pd.to_datetime("2020-08-11")
    EJ_stations = [0, 2, 7, 13, 24, 31, 37, 40, 50, 66, 84, 86, 88, 96, 117, 121, 145, 146, 164, 171, 173, 175, 176, 184, 192, 200, 201, 288, 303, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328]

    ECON_stations = sorted(list(set([0, 366, 346, 386, 335, 30, 108, 161, 192, 115, 392, 360, 389, 380, 3, 330, 331, 37, 344, 120, 337, 376, 351, 202, 288, 336, 367, 355, 193, 194, 377, 114, 164, 374, 361, 119, 144, 299, 97, 156, 33, 17, 110, 163, 196, 111, 306, 152, 108, 161, 113, 253, 100, 158, 304, 373, 36, 88, 359, 297, 357, 98, 157, 143, 369, 338, 26, 176, 128, 31, 356, 147, 350, 15, 165, 391, 400, 362, 363, 146, 365, 305, 383, 67, 68, 173, 106, 160, 19, 353, 240, 385, 26, 176, 252, 388, 184, 213, 190, 394, 395, 5, 200, 47, 22, 345, 27, 251, 364, 2, 210, 13, 280, 67, 68, 173, 169, 189, 289, 334, 266, 348, 122, 387, 107, 381, 379, 397, 50, 399, 281, 203, 109, 162, 172, 358, 106, 160, 270, 214, 330, 331, 329, 290, 398, 9, 10, 11, 12, 198, 195, 1, 80, 81, 174, 175, 85, 86, 23, 24, 99, 153, 370, 390, 341, 384, 98, 157, 343, 347, 354, 371, 25, 342, 97, 156, 145, 67, 68, 173, 368, 20, 396, 340, 378, 1, 80, 81, 174, 175, 85, 86, 372, 167, 21, 96, 100, 158, 114, 164, 339, 276, 332, 393, 333, 43, 215, 60, 352, 7, 84, 303, 349, 375, 382, 46, 218, 82, 83, 401, 402, 403, 404, 405, 402])))
    ECO_stations = [0, 2, 7, 13, 24, 31, 37, 40, 50, 54, 63, 66, 73, 83, 84, 86, 88, 96, 117, 121, 131, 140, 142, 144, 145, 146, 153, 156, 164, 165, 171, 173, 175, 176, 184, 192, 197, 200, 201, 204, 215, 254, 255, 259, 262, 270, 276, 288, 299, 303, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 332, 374, 383, 384, 396, 405]
    ALL_stations = list(range(405+1))
    station_names = ['San Joaquin at Antioch', "Mokelumne River at Benson's Ferry", 'Cache Slough', 'Cache Creek at Yolo', 'Old River at Coney Island', 'Clifton Court', 'Discovery Bay at Indian Slough', 'Doughty Cut above Grant Line Canal', 'Sacramento River at Emmaton', 'Sacramento River at Emmaton', 'Emmaton', 'Emmaton', 'Farrar Park', 'Grant Line Canal at Tracy Rd Bridge', "Green's Landing", 'Harvey O Banks PP', 'Holland Tract', 'Harvey O Banks PP', 'CCWD Old River near Discovery Bay', 'CCWD Rock Slough PP', 'Italian Slough Headwater near Byron', 'Jersey Point', 'Sacramento River at Mallard Island', 'Sacramento River at Mallard Island', 'Middle River at Howard Rd Bridge', 'San Joaquin at Mossdale Bridge', 'Middle River at Tracy Blvd', 'Old River Barrier near DMC (Above)', 'Old River below Dam', 'Old River at Bacon Island', 'Old River at Head', 'Old River at Byron', 'Prisoners Point', 'Rock Slough at Contra Costa Canal', 'San Andreas Landing', 'San Joaquin River Mccune Station near Vernalis', 'Mokelumne River (South Fork) @ Staten Island', 'Sacramento River at Threemile Slough', 'Tom Paine Sl above intake', 'Tom Paine Sl near Pescadero', 'Tom Paine Sl above the mouth', 'Paradise Cut Upstream', 'Tracy Pumping Plant', 'Union Island', 'Victoria Island', 'Barker Slough Pumping Plant', 'Venice Island', 'Sacramento River at Collinsville', 'Sacramento River at Collinsville', 'Sacramento River at Hood', 'Sacramento River at Rio Vista', 'Sacramento River at Martinez', 'Sacramento River at Martinez', 'Chadbourne Slough at Sunrise Duck Club', 'Goodyear Slough at Morrow Island club', "Suisun Slough 300' south of Volanti Slough", 'Montezuma Slough near Beldons Landing', 'Cordelia Slough at Ibis club', 'Yolo Bypass at Lisbon', 'West Canal near Clifton Court Intake', 'Old River near Clifton Court Intake', "Ridge Cut Slough at Knight's Landing", 'Montezuma Slough at National Steel', 'Montezuma Slough at National Steel', 'San Joaquin River near Lathrop', 'San Joaquin River at Brandt Bridge', 'Stockton Ship Channel at Burns Cut-off', 'Stockton Ship Channel at Burns Cut-off', 'Middle River at Undine Road', 'Old River at Tracy Blvd', 'Southampton Shoal Channel LB 6', 'Tiburon Pier', 'China Camp', 'San Francisco', 'Point Reyes', 'Monterey', 'Alameda', 'Redwood City', 'Richmond', 'Antioch', 'Antioch', 'Collinsville', 'Collinsville', 'Contra Costa', 'Pittsburg', 'Pittsburg', 'Rio Vista', 'Vernalis', 'Port Chicago', 'American River at Fair Oaks', 'SF Bay at San Mateo Bridge Near Foster City', 'SF Bay at San Mateo Bridge Near Foster City', 'Guadalupe R above Hw 101 at San Jose', 'Coyote Creek above HW 237', 'San Joaquin R near Vernalis', 'San Joaquin R below Garwood Bridge', 'Turner Cut near Holt', 'Victoria Canal near Byron', 'Middle R at Middle River', 'Middle R near Holt', 'Old R near Delta Mendota Canal', 'Old River Barrier near DMC (Below)', 'Grantline Canal', 'Old R near Byron', 'Old R at Bacon Island', 'Holland Cut near Bethel Island', 'Dutch Sl below Jersey Island', 'Old R at Quimby Island', 'FALSE R near Oakley', 'Old R at Franks Tract', 'San Joaquin R at Prisoners Pt', 'Delta Cross Channel near Walnut Grove', 'Little Potato Slough at Terminous', 'Mokelumne R at Andrus Island', 'Threemile Slough near Rio Vista', 'San Joaquin R at Jersey Point', 'Sacramento R at Freeport', 'Sutter Slough at Courtland', 'Steamboat Slough btw Sacramento R and Sutter Sl', 'Sacramento R above Delta Cross Channel', 'Georgiana Slough near Sacramento R', 'Sacramento R below Georgiana Slough', 'Toe Drain at Liberty Island near Courtland', 'Liberty Cut at Liberty Island near Courtland', 'Miner Slough at HW 84 Bridge', 'Shag Slough at Liberty Island near Courtland', 'Sacramento R Deep Water Ship Channel Near Rio Vista', 'Cache Slough at Ryer Island', 'Sacramento R at Rio Vista', 'Suisun Bay at Benicia Bridge', 'Suisun Bay at Benicia Bridge', 'Carquinez Strait at Carquinez Bridge near Crockett', 'Carquinez Strait at Carquinez Bridge near Crockett', 'Napa R near Napa', 'Petaluma R at Copland Pumping Station', 'San Francisco Bay at Old Dumbarton Bridge', 'San Francisco Bay at Old Dumbarton Bridge', 'San Francisco Bay at Richmond-San Rafael Bridge', 'San Francisco Bay at Richmond-San Rafael Bridge', 'Mare Island', 'Port Chicago', 'Boynton Slough', 'San Joaquin River at Rindge Pump', 'Sacramento R at I Street', 'Georgiana Slough at Mokelumne R', 'Sacramento R at Walnut Grove', 'Sacramento R at Snodgrass', 'Threemile Slough at San Joaquin R', 'Threemile Slough near San Joaquin River', 'Grantline Canal above Dam', 'Old R at Clifton Court Ferry', 'Middle R at Bacon Island', 'Middle R at Middle R', 'Middle River at Union Point', 'Middle R at Mowry', 'Turner Cut near Holt', 'Victoria Canal near Byron', 'Middle R near Holt', 'Grant Line Canal near Clifton Court Forebay - WQ', 'Holland Cut near Bethel Island', 'Old R at Quimby Island', 'FALSE R near Oakley', 'Old R at Franks Tract', 'Mokelumne River near Highway 12', 'Steamboat Slough Below Sutter Slough', 'Old River at Tracy Wildlife Association', 'Rock Slough at Delta Road Bridge', 'Holland Cut at Holland Marina', 'Werner Dredger Cut near Palm Tract', 'Willow Slough Bypass near Davis', 'Piper Slough at Bethal Tract', 'San Joaquin River at Blind Point', 'Rough and Ready Island', 'San Joaquin at Antioch', 'San Joaquin at Antioch', 'San Joaquin at Mossdale Bridge', 'Sacramento River at Fremont Weir (West End)', 'Sacramento River at Fremont Weir (East End)', 'DMC Headworks', 'Sugar Cut', 'Grant Line Canal East', 'Middle River above Barrier', 'Old River above Doughty Cut', 'San Joaquin River above Dos Reis', 'San Francisco Bay at Northeast Shore Alcatraz Island', 'Middle River near Howard Rd Bridge', 'Decker Island', 'Decker Island', 'Cache Slough at Liberty Island', 'Yolo Bypass at Liberty Island', 'Yolo Bypass at Liberty Island (Canal)', 'S Mokelumne R at New Hope BR near Walnut Grove', 'N Mokelumne R near Walnut Grove', 'N Mokelumne R below Snodgrass Slough', 'Steamboat Slough near Sacramento River', "Fisherman's Cut", 'Goodyear Slough at Fleet', 'Sacramento River Downstream of Isleton', 'Miner Slough', 'San Joaquin River at Twitchell Island', 'Sacramento River near Sherman Island', 'Bethel Island at Piper Slough', 'Franks Tract', 'Honker Bay', 'Suisun Bay Cutoff Near Ryer', 'Grizzly Bay', 'Sugar Cut at Golden Anchor', 'Sacramento River at Verona', 'Sacramento River at Verona', 'S.F. Mokelumne River at New Hope Bridge', 'Miner Slough at Five Points', 'Toe Drain at Mallard Road', 'Sacramento River Deep Water Ship Channel Near Freeport', 'Sacramento River Deep Water Ship Channel Near Clarksburg', 'Ulatis Creek Near Elmira', 'Cache Slough Near Hastings Tract Near Rio Vista', 'Cache Slough Above Ryer Island Ferry', 'Suisun Bay At Van Sickle Island', 'Hass Slough Near Elmira', 'Grizzly Bay at Suisun Slough', 'Grizzly Bay at Head of Montezuma Slough Buoy', 'Yolo Bypass Near Woodland', 'Grant Line Canal Near Tracy', 'Sacramento River Deep Water Ship Channel Near Courtland', 'Suisun Bay at Mallard Island', 'Suisun Bay at Mallard Island', 'First Mallard Branch', 'Lisbon Weir', 'Miner Slough Near Sacramento River and Prospect Island', 'Montezuma Slough Above Grizzly Bay', 'Liberty Cut at Liberty Island', 'Alviso Slough', 'Coyote Creek at confluence with Alviso slough', 'Dumbarton Bridge near surface', 'Guadalupe Slough', 'Mowry Slough', 'Newark Slough', 'Pond A8 Outlet at Confluence with Alviso Slough', 'San Mateo Bridge near surface', 'Sacramento Weir Spill to Yolo Bypass', 'San Francisco Bay at Pier 17', 'Martinez-Amorco Pier', 'Alviso Slough Near Alviso', 'South San Francisco Bay at Dumbarton Bridge', 'South San Francisco Bay at Dumbarton Bridge', 'Corte Madera Creek Near Larkspur', 'Old River upstream of Mountain House Creek', 'Paradise Cut Above Old River', 'Paradise Cut', 'Putah Creek near Winters', 'San Joaquin River near Buckley Cove', 'San Joaquin River at D.V.I. Pump', 'San Joaquin River below Paradise Dam', 'Blacklock (NE1)', 'Cygnus-Cordelia Slough', 'Godfather II on Suisun Slough', 'Hunter Cut at Montezuma Slough', 'Montezuma Slough at Roaring River', 'Grizzly Bay Buoy', 'Alameda Creek Flood Channel at Union City', 'Teal Club at Frank Horan Slough', 'Hill Slough', 'American River at H Street Bridge', 'Liberty Island at Upper Stair Step', 'Prospect Slough Near Five Points', 'Toe Drain at Five Points', 'Little Holland Tract at North Breach Near Holland Tract', 'Prospect Slough at Toe Drain Near Courtland', 'Cache Slough below Shag Slough', 'Liberty Cut at Five Points', 'Liberty Cut at Holland Tract', 'Middle River near Tracy Blvd', 'Cosumnes River at Michigan Bar', 'Mokelumne River at Woodbridge', 'American River below Watt Ave Bridge', 'Cache Slough above Ryer Island Ferry', 'Suisun Bay at Channel Marker 16 Near Port Chicago', 'Suisun Bay at Channel Marker 24A Near Bay Point', 'Suisun Bay at Channel Marker 24A Near Bay Point', 'Suisun Bay at Channel Marker 5 at Collinsville', 'Suisun Bay at Channel Marker 10 Near Collinsville', 'Sacramento R Below Toland Landing Near Rio Vista', 'Sacramento R Below Toland Landing Near Rio Vista', 'Sacramento River at Knights Landing', 'Sacramento River above CBD', 'Sacramento River below Wilkins Sl near Grimes', 'Sacramento River above Sacramento Weir', 'San Joaquin River at San Andreas Landing', 'Old River downstream of Tracy WW Outfall', 'Old River at Paradise Cut Confluence Upstream', 'Old River at Paradise Cut Confluence Downstream', 'Old River above Tracy Drain', 'Old River at Bethany Rd Drain', 'Wicklund Cut near Mouth', 'Wicklund Cut at Bethany Rd Bridge', 'Mountain House Creek', 'Tom Paine Slough at Paradise Ave', 'Old River Anchored at ADCP Downstream', 'Old River Flux Station Upstream', 'Paradise Cut Upstream at South Bridge', 'Paradise Cut Upstream at North Bridge', 'Grant Line Canal West', 'Drainage at Arbor Road', 'Woodward Cut', 'Railroad Cut North', 'Railroad Cut South', 'JT_Clarksburg_Sac River         River', 'JT_Hood_Sac River         River', 'JT_Courtland_Sac River         River', 'JT_Locke_Sac River         River', 'JT_Walnut Grove Cross Channel_Sac River', 'JT_Old Walnut Grove_Snodgrass Slough', "JT_Wimpy's Marina_Mokelumne Confluence", 'JT_Ryde_Sac River', 'JT_Trailer Park_Sac River', 'JT_Isleton_Sac River', 'JT_Vieras Resort_Sac River', 'JT_Snug Harbor Marina_Steamboat Slough', 'JT_Brannan Marinas_Mokelumne SJ Confluence', 'JT_Brannan Marinas_San Joaquin River', 'JT_Dutch Slough', 'JT_Taylor Dutch Slough Confluence', 'JT_Taylor Slough', 'JT_Willow Park Marina_Sand Mound Slough', 'JT_Summer Lake_Sand Mound Slough', 'JT_Bethel Island_Delta Coves', 'JT_King Island Marina Trailer Park_White Slough', 'JT_Orowood_Old River', 'YOLO BYPASS (DLIS-20)', 'YOLO BYPASS (DLIS-20)', 'YOLO BYPASS (DLIS-20)', 'HASTINGS TRACT', 'HASTINGS TRACT', 'NETHERLANDS', 'KASSON DISTRICT', 'BRANNAN-ANDRUS', 'MERRITT ISLAND', 'MCMULLIN RANCH', 'GALT-MOKELUMNE SOUTH SACRAMENTO COUNTY AREA (DLIS-18)', 'DISCOVERY BAY AREA (DLIS-08)', 'UNION ISLAND EAST', 'MIDDLE & UPPER ROBERTS ISLAND', 'UNION ISLAND WEST', 'ROUGH AND READY ISLAND', 'DREXLER TRACT', 'HONKER LAKE TRACT', 'UNION ISLAND WEST', 'GLANVILLE', 'SOUTH DELTA AGGREGATE AREA', 'RANDALL ISLAND', 'MERRITT ISLAND', 'MAINTENANCE AREA 9 NORTH', 'LISBON DISTRICT', 'UNION ISLAND WEST', 'TYLER ISLAND', 'STEWART TRACT', 'PESCADERO DISTRICT', 'MILDRED ISLAND', 'PESCADERO DISTRICT', 'GRAND ISLAND', 'SUTTER ISLAND', 'UPPER ANDRUS ISLAND', 'UPPER ANDRUS ISLAND', 'NEW HOPE TRACT', 'STATEN ISLAND', 'DREXLER POCKET', 'BRANNAN-ANDRUS', 'LODI (DLIS-16)', 'MCMULLIN RANCH', 'UNION ISLAND EAST', 'MIDDLE & UPPER ROBERTS ISLAND', 'VEALE TRACT', 'WOODWARD ISLAND', 'SUTTER ISLAND', 'SOUTH DELTA AGGREGATE AREA', 'MERRITT ISLAND', 'PEARSON DISTRICT', 'KNIGHTSEN AREA (DLIS-07)', 'DUTCH SLOUGH', 'GRAND ISLAND', 'DUTCH SLOUGH', 'SOUTH DELTA AGGREGATE AREA', 'FABIAN TRACT', 'UNION ISLAND EAST', 'LISBON DISTRICT', 'KASSON DISTRICT', 'WALNUT GROVE', 'RECLAMATION DISTRICT 17', 'GRAND ISLAND', 'UNION ISLAND EAST', 'UPPER ANDRUS ISLAND', 'GRAND ISLAND', 'HASTINGS TRACT', 'CACHE HAAS AREA', 'CACHE HAAS AREA', 'BYRON AREA (DLIS-09)', 'MCCORMACK-WILLIAMSON TRACT', 'DECKER ISLAND', 'DONLON ISLAND (DLIS-05)', 'UPPER ANDRUS ISLAND', 'NORTH DELTA AGGREGATE AREA', 'OAKLEY AREA (DLIS-06)', 'VEALE TRACT', 'PESCADERO DISTRICT', 'KING ISLAND']

    stations_set = ALL_stations
    if stations_set_name == "ECON":
      stations_set = ECON_stations
    elif stations_set_name == "EJ":
      stations_set = EJ_stations
    elif stations_set_name == "ECO":
      stations_set = ECO_stations

    df = pd.read_csv(path, sep=r'\s+', dtype=np.float32, usecols=stations_set)
    df.columns = ["time"] + [f"{i}_{station_names[i-1]}" for i in stations_set[1:]]

    df['time'] = start_time + pd.to_timedelta(df['time'], unit='s')

    return df

  folder_path = "drive/Shareddrives/JT_DataAccess/Data"
  # folder_path='/content/drive/MyDrive/MRPI 2023/1) Major Projects & Assignments/2) Hydrodynamics Modeling/Files/SCHISM_output/2025_Oct_inflow/'
  data_dict ={}
  # for filename in tqdm(os.listdir(folder_path), desc='Loading Files'):
  #     if filename.endswith('.csv'):
  #         file_path = os.path.join(folder_path, filename)
  #         # print(f"Now processing: {filename}")
  #         df = read_csv_file(file_path)
  #         data_dict[filename] = df
  for filename in titles:
    file_path = os.path.join(folder_path, filename)
    df = read_csv_file(file_path)
    data_dict[filename] = df
  return data_dict


Run_ids_options = ["15","16","17"]
variable_options = ["salinity_raw","temp_raw", "elev_raw","w_raw","v_raw","u_raw"]
run_label = widgets.HTML("<b>Select a Run ID</b>")
Run_id = [widgets.Checkbox(value=False, description=o) for o in Run_ids_options]
Run_id_checkbox_group = widgets.VBox([run_label]+Run_id)

var_label = widgets.HTML("<b>Select a variable</b>")
variable = [widgets.Checkbox(value=False, description=o) for o in variable_options]
variable_checkbox_group = widgets.VBox([var_label]+variable)
# Run_id_checkbox_group.layout.display = "none"###
# variable_checkbox_group.layout.display = "none"###
# toggle_options = widgets.ToggleButton(
#     value=False,
#     description='Show Run Id and Variable',
#     icon='eye'
# )#####

# def toggle_visibility(change):####
#     if change["new"]:
#         Run_id_checkbox_group.layout.display = "block"
#         variable_checkbox_group.layout.display = "block"
#         toggle_options.description = "Hide Options"
#         toggle_options.icon = "eye-slash"
#     else:
#         Run_id_checkbox_group.layout.display = "none"
#         variable_checkbox_group.layout.display = "none"
#         toggle_options.description = "Show Options"
#         toggle_options.icon = "eye"

# toggle_options.observe(toggle_visibility, "value")###
stations_set_selection = widgets.Dropdown(
    options=['ECON', 'EJ', 'ECO', 'ALL'],
    value='ALL',           # default value
    description='Choose a station set:',
    disabled=False,
    style={'description_width': '150px'}
)

sd_date_picker = widgets.DatePicker(description='Start Date:', value=date(2020, 10, 1)) # Initialize with a valid default date
sd_time_picker = widgets.Text(description='Start Time:', placeholder='HH:MM:SS', value='00:30:00') # Add a default time
end_date_picker = widgets.DatePicker(description='End Date:',value=date(2022, 1, 1))   # Initialize with a valid default date
end_time_picker = widgets.Text(description='End Time:', placeholder='HH:MM:SS', value='23:00:00') # Add a default time

convert_to_EC_chk = widgets.Checkbox( # unit conversion to EC
    value=True,        # initial value
    description='Convert PSU to EC (only applied to salinity_raw) - Ignores negative PSU values',
    indent=False,
    layout=widgets.Layout(width='auto'),
    style={'description_width': '500px'}
)

thresholds = []
for var in variable_options:
  threshold_chk = widgets.Checkbox( # unit conversion to EC
      value=False,        # initial value
      description=var,
      indent=False,
      layout=widgets.Layout(width='100px')
  )
  threshold_dropdown = widgets.Dropdown(###
      options=['<', '>', '='],
      value=None,
      description='',
      layout=widgets.Layout(width='150px')

  )###
  threshold_input = widgets.FloatText(
      value=0.0,
      description='',
      disabled=False,
      layout=widgets.Layout(width='150px')
  )
  threshold_row = widgets.HBox([
      threshold_chk, threshold_dropdown, threshold_input
  ])
  thresholds.append(threshold_row)

thresholds_label = widgets.HTML("<b>Thresholds</b>")
thresholds_alert = widgets.HTML("<b>Care for the unit! Thresholding is done AFTER unit conversion</b>")

thresholds = widgets.VBox([thresholds_label, thresholds_alert]+thresholds)
filtering_dropdown = widgets.Dropdown(###
    options=['None', 'Daily Maximum'],
    value=None,
    description='Filtering Method',
    style={'description_width': '100px'}
)###

MEAN = widgets.Dropdown(###
    options=['Overall Mean', 'Monthly Mean', 'Daily Mean', '15 Minutes (Raw)'],
    value=None,
    description='Type of Mean:',
    style={'description_width': '100px'}
)###

dropdowns_row = widgets.HBox([
    Run_id_checkbox_group,
    variable_checkbox_group,
    sd_date_picker,
    sd_time_picker,end_date_picker,end_time_picker,MEAN
])

# submit_button = widgets.Button(
#     description='Submit',
#     button_style='primary',
#     icon='check'
# )
download_button = widgets.Button(
    description='Download as .csv',
    button_style='primary',
    icon='check'
)
preview_button = widgets.Button(
    description='Preview as Table',
    button_style='primary',
    icon='check'
)
output = widgets.Output()
# def on_submit_clicked(b):
#     with output:
#         output.clear_output()
#         run_selected_checks = [cb.description for cb in Run_id if cb.value]
#         var_selected_checks = [cb.description for cb in variable if cb.value]
#         print(f"Selected Checkboxes: {run_selected_checks}")
#         print(f"Dropdown 2: {var_selected_checks}")
#         print(f"Name: {sd_date_picker.value,sd_time_picker.value}")
#         print(f"Name: {end_date_picker.value,end_time_picker.value}")
#         title = get_file_name(run_selected_checks,var_selected_checks)
#         starts_date = get_starts_date(sd_date_picker.value,sd_time_picker.value)
#         mean = MEAN.value###
#         end_date = get_end_date(end_date_picker.value,end_time_picker.value)
#         print_data(title, database,starts_date,end_date,mean)###

def on_download_clicked(b):
    global global_dfs, global_fnames
    with output:
        # output.clear_output()
        run_selected_checks = [cb.description for cb in Run_id if cb.value]
        var_selected_checks = [cb.description for cb in variable if cb.value]
        # print(f"Selected Checkboxes: {run_selected_checks}")
        # print(f"Dropdown 2: {var_selected_checks}")
        # print(f"Name: {sd_date_picker.value,sd_time_picker.value}")
        # print(f"Name: {end_date_picker.value,end_time_picker.value}")
        title = get_file_name(run_selected_checks,var_selected_checks)
        stations_set_name = stations_set_selection.value
        starts_date = get_starts_date(sd_date_picker.value,sd_time_picker.value)
        filter_method = filtering_dropdown.value
        mean_value = MEAN.value###
        threshold_selections = {}
        for threshold_UIs in thresholds.children[2:]:
          chk, op, val = threshold_UIs.children   # unpack HBox
          threshold_selections[chk.description] = {
              "enabled": chk.value,
              "operation": op.value,
              "value": val.value
          }
        end_date = get_end_date(end_date_picker.value,end_time_picker.value)
        convert_to_EC = convert_to_EC_chk.value

        if len(global_dfs) == 0 or check_UI_selection_changed():
          update_UI_selection()
          output.clear_output()
          global_dfs, global_fnames = get_dfs(title,stations_set_name,starts_date,end_date,threshold_selections,filter_method,mean_value,convert_to_EC)
        download_multiple_as_zip(global_dfs, global_fnames, "JT_DataAccess.zip")
        # for (df,fname) in zip(*get_dfs(title,stations_set_name,starts_date,end_date,mean_value)):
        #   csv_str = df.to_csv(index=False)
        #   download_data(csv_str, filename=fname)

def on_preview_clicked(b):
    global global_dfs, global_fnames
    with output:
        output.clear_output()
        run_selected_checks = [cb.description for cb in Run_id if cb.value]
        var_selected_checks = [cb.description for cb in variable if cb.value]
        # print(f"Selected Checkboxes: {run_selected_checks}")
        # print(f"Dropdown 2: {var_selected_checks}")
        # print(f"Name: {sd_date_picker.value,sd_time_picker.value}")
        # print(f"Name: {end_date_picker.value,end_time_picker.value}")
        titles = get_file_name(run_selected_checks,var_selected_checks)
        stations_set_name = stations_set_selection.value
        starts_date = get_starts_date(sd_date_picker.value,sd_time_picker.value)
        filter_method = filtering_dropdown.value
        mean_value = MEAN.value###
        threshold_selections = {}
        for threshold_UIs in thresholds.children[2:]:
          chk, op, val = threshold_UIs.children   # unpack HBox
          threshold_selections[chk.description] = {
              "enabled": chk.value,
              "operation": op.value,
              "value": val.value
          }
        end_date = get_end_date(end_date_picker.value,end_time_picker.value)
        convert_to_EC = convert_to_EC_chk.value
        update_UI_selection()
        global_dfs, global_fnames = get_dfs(titles,stations_set_name,starts_date,end_date,threshold_selections,filter_method,mean_value,convert_to_EC)
        preview_tables(global_dfs, global_fnames)
        # download_multiple_as_zip(dfs, fnames, "JT_DataAccess.zip")
        # for (df,fname) in zip(*get_dfs(title,stations_set_name,starts_date,end_date,mean_value)):
        #   csv_str = df.to_csv(index=False)
        #   download_data(csv_str, filename=fname)

def check_UI_selection_changed():
    global previous_UI_states
    # check run selection
    for i in range(len(Run_id)):
      if Run_id[i].value != previous_UI_states['Run_id'][i]:
        return True
    # check var selection
    for i in range(len(variable)):
      if variable[i].value != previous_UI_states['variable'][i]:
        return True
    # check station set selection
    if stations_set_selection.value != previous_UI_states['stations_set_selection']:
      return True

    # check start date
    if sd_date_picker.value != previous_UI_states['sd_date_picker']:
      return True
    # check start time
    if sd_time_picker.value != previous_UI_states['sd_time_picker']:
      return True
    # check end date
    if end_date_picker.value != previous_UI_states['end_date_picker']:
      return True
    # check end time
    if end_time_picker.value != previous_UI_states['end_time_picker']:
      return True

    # check thresholds
    if threshold_chk.value != previous_UI_states['threshold_chk']:
      return True
    if threshold_dropdown.value != previous_UI_states['threshold_dropdown']:
      return True
    if threshold_input.value != previous_UI_states['threshold_input']:
      return True

    # check Filtering method selection
    if filtering_dropdown.value != previous_UI_states['filtering_dropdown']:
      return True
    # check MEAN method selection
    if MEAN.value != previous_UI_states['MEAN']:
      return True
    # check convert to EC
    if convert_to_EC_chk.value != previous_UI_states['convert_to_EC_chk']:
      return True
    return False

# updates global variables
def update_UI_selection():
    global previous_UI_states
    previous_UI_states = {
        "Run_id": [r.value for r in Run_id],
        "variable": [v.value for v in variable],
        "stations_set_selection": stations_set_selection.value,
        "sd_date_picker": sd_date_picker.value,
        "sd_time_picker": sd_time_picker.value,
        "end_date_picker": end_date_picker.value,
        "end_time_picker": end_time_picker.value,
        "threshold_chk": threshold_chk.value,
        "threshold_dropdown": threshold_dropdown.value,
        "threshold_input": threshold_input.value,
        "filtering_dropdown": filtering_dropdown.value,
        "MEAN": MEAN.value,
        "convert_to_EC_chk": convert_to_EC_chk.value
    }
    pass

def preview_tables(dfs, fnames):
  print("previewing...", fnames)
  print("\n\n\n")
  # dt.DataTable.max_columns = 200
  # dt.DataTable.max_rows = 300
  # tables = [dt.DataTable(df) for df in dfs]
  # display(tables[0])
  # for df in dfs:
  #   table = dt.DataTable(df)
  #   display(table)
  max_rows = 100
  max_cols = 100
  html = ""
  for df, fname in zip(dfs, fnames):
      df_preview = df.iloc[:max_rows, :max_cols]

      html += "preview of " + fname
      html += df_preview.to_html() + "<br><hr><br>"
  display(HTML(html))

def download_data(csv_str, filename="data.csv"):
    with open(filename, 'w') as f:
        f.write(csv_str)
    files.download(filename)

def download_multiple_as_zip(dfs, fnames, zip_name="output.zip"):
    print("preparing files to download... (downloading multiple files will take longer)")
    # create in-memory zip file
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        for df, name in zip(dfs, fnames):
            csv_bytes = df.to_csv(index=False).encode("utf-8")
            zf.writestr(name, csv_bytes)

    # save file to disk
    with open(zip_name, "wb") as f:
        f.write(zip_buffer.getvalue())
    files.download(zip_name)

download_button.on_click(on_download_clicked)
preview_button.on_click(on_preview_clicked)

ui = widgets.VBox([
    stations_set_selection,
    widgets.HBox([Run_id_checkbox_group, variable_checkbox_group]),
    convert_to_EC_chk,
    widgets.HBox([sd_date_picker,sd_time_picker]),
    widgets.HBox([end_date_picker,end_time_picker]),
    thresholds,
    filtering_dropdown,
    MEAN,###
    widgets.HBox([preview_button, download_button]),
    # submit_button,
    output
])


def get_file_name(ID,VARS):
  mylist=[]
  for i in ID:
    for v in VARS:
      name = (f"run_{i}_{v}"+ ".csv")
      mylist.append(name)
  return mylist

def get_starts_date(date,time):
  starts_date = datetime.strptime(f"{date} {time}", "%Y-%m-%d %H:%M:%S")
  return starts_date

def get_end_date(date,time):
  end_date = datetime.strptime(f"{date} {time}", "%Y-%m-%d %H:%M:%S")
  return end_date

def get_dfs(titles, stations_set_name, start, end, threshold_selections, filter_method,TMEAN, convert_to_EC):
  # print(titles, stations_set_name)
  ret, fnames = [], []
  print("initalizing database...")

  database = initialize(titles, stations_set_name)
  print("database initalized.")

  print("preparing data... (expect 1-2 minutes)")

  for item in titles:
    print(f"\t preparing {item}...")
    fname = item.split('.')[0]
    data = database[item]

    # Subset the cols

    data = (data[(data['time'] >= start) & (data['time'] <= end)])
    data_filtered = data.replace([-999, -9999], np.nan) # exclusion

    # Convert PSU â†’ EC if requested
    filename_unit = ""
    variable = "_".join(fname.split("_")[2:])
    if 'salinity_raw' == variable:
      filename_unit = "PSU"
    if convert_to_EC and 'salinity_raw' == variable:
      numeric_cols = data_filtered.select_dtypes(include=[np.number]).columns
      data_filtered[numeric_cols] = data_filtered[numeric_cols].apply(
          lambda col: col.apply(psu_to_ec)
      )
      filename_unit = "EC"

    # further filter by threshold if requested
    print(threshold_selections)
    if threshold_selections[variable]['enabled']:
      op = threshold_selections[variable]['operation']
      threshold_value = threshold_selections[variable]['value']
      # get numeric columns only
      numeric_cols = data_filtered.select_dtypes(include=[np.number]).columns

      if op == "<":
        # Mask only on numeric columns
        mask_num = (data_filtered[numeric_cols] < threshold_value)
      elif op == ">":
        # Mask only on numeric columns
        mask_num = (data_filtered[numeric_cols] > threshold_value)
      elif op == "=":
        mask_num = (data_filtered[numeric_cols] == threshold_value)

      # Step 1: keep only numeric columns that satisfy the condition
      num_cols_to_keep = mask_num.any(axis=0)

      # Keep ALL non-numeric columns
      non_numeric_cols = [c for c in data_filtered.columns if c not in numeric_cols]

      # Construct final column list
      final_columns = non_numeric_cols + num_cols_to_keep[num_cols_to_keep].index.tolist()

      # Step 2: keep rows that satisfy the condition (based on kept numeric columns)
      rows_to_keep = mask_num.loc[:, num_cols_to_keep].any(axis=1)
      data_filtered = data_filtered.loc[rows_to_keep, final_columns]

    if filter_method == "Daily Maximum":
      data_filtered = data_filtered.resample('D', on='time').max().reset_index()
      fname += "_Daily_Maximum"

    if TMEAN == "Overall Mean":
      df = data_filtered.mean(numeric_only=True).reset_index()
      df.columns = ['Stations', 'Overall Mean']
      fname += "_Overall_Mean"

    if TMEAN == "Monthly Mean":
      df = data_filtered.resample('M', on='time').mean().reset_index()
      fname += "_Monthly_Mean"

    if TMEAN == "Daily Mean":
      df = data_filtered.resample('D', on='time').mean().reset_index()
      fname += "_Daily_Mean"

    if TMEAN == "15 Minutes (Raw)":
      df = data_filtered
      fname += "_15_Minutes_Raw"

    ret.append(df)
    fnames.append(f"{fname}_processed_{filename_unit}.csv")


  return ret, fnames



def psu_to_ec(psu):
  # equation comes from https://docs.google.com/spreadsheets/d/1LSa0cf3rykRH2dh1cksAucCe70GzwLg83LmE9ZBs6JU/edit?gid=1508836761#gid=1508836761
  try:
    if np.isnan(psu):
        return np.nan
    ec= (psu / 35) * 53087 + psu * (psu - 35) * (
        -16.072
        + 4.1495 * math.sqrt(psu)
        - 0.5345 * psu
        + 0.0261 * (psu ** 1.5)
    )
    return ec
  except Exception as e:
    print(psu, e)

display(ui)